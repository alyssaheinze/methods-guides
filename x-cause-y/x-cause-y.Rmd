---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 stratégies pour déterminer si X cause Y" -->
<!-- author: "Auteur du guide des méthodes: Macartan Humphreys" -->

Résumé
==
Les expériences sont un moyen de déterminer si quelque chose cause quelque chose d'autre.
L'idée de base est : essayez-le et découvrez-le.
La chose délicate est de trouver comment l'essayer d'une manière qui permette d'avoir assez confiance pour croire les effets causaux.
L'intervention randomisée est une stratégie qui occupe une place de choix dans la boîte à outils du chercheur.
C'est la stratégie qui est au cœur de la plupart des recherches expérimentales menées par les membres de EGAP.
Mais il existe d'autres stratégies qui sont parfois plus appropriées.
Nous décrivons ici les dix stratégies les plus importantes pour déterminer les effets causaux.
^[Auteur d'origine : Macartan Humphreys. Révisions mineures : Winston Lin, 30 août 2016. Le guide est un document vivant et sujet à une mise à jour par les membres de EGAP à tout moment ; les contributeurs répertoriés ne sont pas responsables des modifications ultérieures.]

1. Randomisation
==
La stratégie utilisée dans les essais randomisés contrôlés (ou interventions randomisées ou expériences randomisées) consiste à utiliser une forme de loterie pour déterminer qui, parmi un groupe, aura ou n'aura pas accès à un traitement ou à un programme (ou peut-être qui l'aura d'abord et qui l'obtiendra plus tard, ou qui obtiendra une version et qui en obtiendra une autre).
L'élégance de l'approche est qu'elle utilise le hasard pour déterminer quels sont les effets systématiques d'un programme.
Le caractère aléatoire réduit le risque qu'une relation observée entre le traitement et les résultats soit due à des "facteurs de confusion" - i.e. d'autres différences entre les groupes (par exemple, on pourrait craindre que les choses s'améliorent dans les zones de traitement précisément parce que les programmes choisissent de bien fonctionner, mais savoir que la sélection est aléatoire efface complètement cette préoccupation).
Il est puissant car il garantit qu'il n'y a pas de relation systématique entre le traitement et toutes les autres caractéristiques qui peuvent affecter les résultats, que vous en soyez conscient ou non.
Pour cette raison, il est souvent considéré comme l'étalon-or.
Cependant, la randomisation ne peut pas être utilisée toujours et partout, à la fois pour des raisons éthiques et pratiques.
Mais il peut être utilisé dans beaucoup plus de situations que les gens ne le pensent.
Voir [Humphreys et Weinstein](http://www.columbia.edu/~mh2245/papers1/HW_ARPS09.pdf) pour une discussion sur les forces et les limites de l'approche en économie politique du développement.

2. Contrôle expérimental (homogénéité unitaire induite)
==
Une deuxième stratégie plus utilisée en laboratoire et également en sciences physiques consiste à utiliser un contrôle expérimental pour s'assurer que deux unités sont identiques à tous les égards pertinents, à l'exception du traitement.
Par exemple, si vous vouliez voir si une balle lourde tombe plus vite qu'une balle plus légère, vous pouvez vous assurer qu'elles ont la même forme et la même taille et les laisser tomber toutes les deux en même temps, dans les mêmes conditions météorologiques, et ainsi de suite.
Vous attribuez ensuite toute différence de résultats à la caractéristique que vous n'avez pas maintenue constante entre les deux unités.
Cette stratégie est fondamentalement différente de celle utilisée dans les essais randomisés.
Dans les essais randomisés, vous abandonnez normalement l'idée de tout garder fixe et cherchez plutôt à vous assurer que la variation naturelle - sur des variables que vous pouvez ou ne pouvez pas observer - ne produit pas de biais dans vos estimations ; en outre, vous cherchez normalement à évaluer les effets moyens pour une gamme de conditions de fond plutôt que pour un ensemble fixe de conditions de fond.
Les mérites de l'approche de contrôle dépendent de votre confiance dans le contrôle effectif de tous les facteurs pertinents ; si vous ne pouvez pas, alors une approche randomisée peut être supérieure.

3. Expériences naturelles (randomisation comme-si)
==
Parfois, les chercheurs ne sont pas en mesure de randomiser, mais l'inférence causale est toujours possible car la nature a fait la randomisation pour vous.
La caractéristique clé de l'approche "expérience naturelle" est que vous avez des raisons de croire que la variation de certains traitements naturels est "pseudo aléatoire". Par exemple, disons que les places dans une école sont attribuées par tirage au sort.
Ensuite, vous pourrez peut-être analyser les effets de la fréquentation scolaire comme s'il s'agissait d'un essai randomisé contrôlé.
Une étude intelligente des effets des conflits sur les enfants par [Annan et Blattman](http://www.chrisblattman.com/documents/research/2010.Consequences.RESTAT.pdf) a utilisé le fait que la Lord’s Resistance Army (LRA) en Ouganda a enlevé des enfants de façon assez aléatoire.
Une autre étude intelligente sur les programmes de Désarmement, Démobilisation et Réintégration (DDR) par [Gilligan, Mvukiyehe et Samii](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1911968) a utilisé le fait que les opérations d'une ONG ont été interrompues en raison d'un différend contractuel, ce qui a donné lieu à un groupe témoin "naturel" d'ex-combattants qui n'ont pas bénéficié de programmes de démobilisation.
Voir [le livre de Dunning](http://www.cambridge.org/us/academic/subjects/politics-international-relations/research-methods-politics/natural-experiments-social-sciences-design-based-approach) pour trouver et analyser des expériences naturelles.

4. Comparaisons avant/après
==
Souvent, la première chose vers laquelle les gens se tournent pour déterminer les effets causaux est la comparaison des unités avant et après le contrôle.
Ici, vous utilisez le passé comme un contrôle pour le présent.
L'idée de base est très intuitive : vous éteignez la lumière et vous voyez la lumière s'éteindre ; attribuer le changement de lumière à l'action semble facile même en l'absence de toute randomisation ou contrôle.
Mais pour de nombreuses interventions sociales, l'approche n'est pas si fiable, en particulier dans des environnements changeants.
Le problème est que les choses s'améliorent ou empirent pour de nombreuses raisons sans rapport avec les traitements ou les programmes qui vous intéressent.
En fait, il est possible qu'en raison de toutes les autres choses qui changent, les choses peuvent empirer dans un domaine du programme même si les programmes ont eu un effet positif (donc les choses empirent mais ne sont toujours pas aussi mauvaises qu'elles l'auraient été sans le programme!).
Une approche plus sophistiquée que la simple comparaison avant/après est appelée "méthode des doubles différences" – en gros, vous comparez la différence avant/après dans les zones de traitement avec celles dans les zones de contrôle.
C'est une bonne approche mais vous devez toujours être sûr que vous avez de bons groupes de contrôle et en particulier que les groupes de contrôle et de traitement ne sont pas susceptibles de changer différemment pour des raisons autres que le traitement.

5. Contrôle ex post I : régression
==
L'approche la plus courante de l'identification causale dans les travaux statistiques appliqués est peut-être l'utilisation de la régression multiple pour contrôler les facteurs de confusion possibles.
L'idée est d'essayer d'utiliser toutes les informations dont vous disposez sur les raisons pour lesquelles les zones de traitement et de contrôle ne sont pas facilement comparables et d'ajuster statistiquement ces différences.
Cette approche fonctionne bien dans la mesure où vous pouvez déterminer et mesurer les facteurs de confusion et comment ils sont liés au traitement, mais n'est pas bonne si vous ne savez pas quels sont les facteurs de confusion.
En général, nous ne savons tout simplement pas quels sont tous les facteurs de confusion et cela expose cette approche à toutes sortes de biais (en effet, si vous contrôlez les mauvaises variables, il est possible *d'introduire* un biais là où il n'y en avait pas auparavant).


6. Contrôle ex post II: Matching and Weighting
==
A variety of alternative approaches seek to account for confounding variables by carefully matching treatment units to one or many control units.
Matching has some advantages over regression (for example, estimates can be less sensitive to choices of functional form), but the basic idea is nevertheless similar, and indeed matching methods can be implemented in a regression framework using appropriate weights.
Like regression, at its core, this strategy depends on a conviction that there are no important confounding variables that the researcher is unaware of or is unable to measure.
Specific methods include:

* [optimal full- and pair-matching](http://dept.stat.lsa.umich.edu/~bbh/hansen2004.pdf) and see the [optmatch package](https://github.com/markmfredrickson/optmatch)
* [optimal pair-matching with fine-balance via mixed integer programming](https://projecteuclid.org/euclid.aoas/1396966284) [See also the designmatch package](https://cran.rstudio.com/web/packages/designmatch) and the [paper comparing approaches](http://jrzubizarreta.com/evaluation.pdf)
* [optimal multi-level matching (for designs with schools and students)](https://projecteuclid.org/euclid.aoas/1536652962)
* [sparse optimal matching](https://www.stat.berkeley.edu/~spi/software.html)
* [generalized full matching](https://arxiv.org/abs/1703.03882)
* [coarsened exact matching](http://gking.harvard.edu/cem)
* [genetic matching](http://sekhon.berkeley.edu/papers/GenMatch.pdf)
* [entropy balancing](http://web.stanford.edu/~jhain/Paper/PA2012.pdf)
* [inverse propensity weighting](http://pan.oxfordjournals.org/content/18/1/36.short)
* [stable balancing weights](http://www.columbia.edu/~jz2313/sbw.pdf), and the use of
* [synthetic controls](http://web.stanford.edu/~jhain/Paper/AJPS2015a.pdf).

7. Instrumental variables (IV)
==
A very different approach to estimating causal effects can be used if researchers can find some feature that explains why a given group got a treatment but which is otherwise unrelated to the outcome of interest.
Such a feature is called an instrument.
For example say you are interested in the effect of a livelihoods program on employment, and say it turned out that most people who got access to the livelihoods program did so because they were a relative of a particular program officer.
Then, if there were no other ways that being a relative of this person could be related to job prospects, then you can work out the effect of the program by working out the effect of being a relative of this individual on job prospects.
This has been a fairly popular approach but some of the enthusiasm for this has died a bit, basically because it is hard to find a good instrument.
One smart application to look at the effects of poverty on conflict used rainfall in Africa as an instrument for income/growth.
While there are worries that the correlation between conflict and poverty may be due to the fact that conflict might cause poverty, it does not seem plausible that conflict causes rainfall! So using rainfall as an instrument here gave a lot more confidence that really there is a causal, and not just correlational, relationship between [poverty and conflict](http://emiguel.econ.berkeley.edu/research/economic-shocks-and-civil-conflict-an-instrumental-variables-approach).

8. Regression discontinuity designs (RDD)
==
The regression discontinuity approach is one of the most underused approaches but it has tremendous potential.
The strategy works as follows.
Say that some program is going to be made available to a set of potential beneficiaries.
These potential beneficiaries are all ranked on a set of relevant criteria, such as prior education levels, employment status, and so on.
These criteria can be quantitative; but they can also include qualitative information such as assessments from interviews.
These individual criteria are then aggregated into a single score and a threshold is identified.
Candidates scoring above this threshold are admitted to the program, while those below are not.
"Project" and "comparison" groups are then identified by selecting applicants that are close to this threshold on either side.
Using this method we can be sure that treated and control units are similar, at least around the threshold.
Moreover, we have a direct measure of the main feature on which they differ (their score on the selection criteria).
This information provides the key to estimating a program effect from comparing outcomes between these two groups.
The advantage of this approach is that all that is needed is that the implementing agency uses a clear set of criteria (which can be turned into a score) upon which they make treatment assignment decisions.
The disadvantage is that really reliable estimates of impact can only be made for units right around the threshold.
For overviews of RDD, see [Skovron and Titiunik](http://www-personal.umich.edu/~titiunik/papers/SkovronTitiunik2015.pdf) and [Lee and Lemieux](http://econ.sites.olt.ubc.ca/files/2014/02/Lee-Lemieux-rev.pdf); for two interesting applications, see [Manacorda et al. on Uruguay](http://emiguel.econ.berkeley.edu/research/government-transfers-and-political-support) and [Samii on Burundi](http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=8963107).

9. Process tracing
==
In much qualitative work researchers try to establish causality by looking not just at whether being in a program is associated with better outcomes but (a) looking for steps in the process along the way that would tell you whether a program had the effects you think it had and (b) looking for evidence of other outcomes that should be seen if (or perhaps: if and only if) the program was effective.
For example not just whether people in a livelihoods program got a job but whether they got trained in something useful, got help from people in the program to find an employer in that area, and so on.
If all these steps are there, that gives confidence that the relationship is causal and not spurious.
If a program was implemented but no one actually took part in it, this might give grounds to suspect that any correlation between treatment and outcomes is spurious.
The difficulty with this approach is that it can be hard to know whether any piece of within-case evidence has probative value.
For example a program may have positive (or negative) effects through lots of processes that you don’t know anything about and processes that you think are important, might not be.
See [Humphreys and Jacobs](http://www.columbia.edu/%7Emh2245/papers1/BIQQ.pdf) for a description of the Bayesian logic underlying process tracing and illustrations of how to combine it with other statistical approaches.

10. Front Door Strategies (Argument from mechanisms)
==
A final approach, conceptually close to process tracing, is to argue from mechanisms.
Say you know only $A$ can cause $C$ only through $B$.
Say moreover that you know that no third things cause both $B$ and $C$ (other than, perhaps, via $A$) and no third things cause both $A$ and $B$.
Then covariation between $A$ and $B$ and between $B$ and $C$ can be used to assess the effect of $A$ on $C$.
The advantage is that causality can be established even in the presence of confounders — for example even if unobserved variables cause both $A$ and $C$.
The difficulty however is that the strategy requires a lot of confidence in your beliefs about the structure of causal relations.
For more see [Pearl (2000)](https://books.google.com/books?id=wnGU_TsW3BQC&hl=en).
