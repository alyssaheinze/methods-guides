---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 choses √† savoir sur l'inf√©rence causale" -->
<!-- author: "Auteur du guide des m√©thodes: Macartan Humphreys" -->

Abstract
==
Le philosophe David Lewis a d√©crit la causalit√© comme "quelque chose qui fait une diff√©rence, et cette diff√©rence doit √™tre une diff√©rence par rapport √† ce qui se serait pass√© sans elle."[^1] Ceci est l'interpr√©tation de la causalit√© pour la plupart des exp√©rimentalistes. M√™me si la d√©finition semble simple, elle a de nombreuses implications subtiles. Voici dix id√©es impliqu√©es par cette notion de causalit√© qui importent pour le design de recherche.
^[Originating author: Macartan Humphreys. Minor revisions: Winston Lin and Donald P. Green, 24 Jun 2016. Revisions MH 6 Jan 2020. Revisions Anna Wilke May 2021. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits.]

[^1]: Lewis, David. "Causation." The journal of philosophy (1973): 556-567.

1. Une assertion causale est une d√©claration sur ce qui ne s'est pas produit.
==
Pour la plupart des exp√©rimentateurs, la d√©claration "$X$ a caus√© $Y$" signifie que $Y$ est pr√©sent *et* $Y$ n'aurait pas √©t√© pr√©sent si $X$ n'avait pas √©t√© pr√©sent.
Cette d√©finition requiert une notion de ce qui aurait pu arriver, mais ne s'est pas produit.[^2]
De m√™me, l'"effet" de $X$ sur $Y$ est consid√©r√© comme la diff√©rence entre la valeur que $Y$ aurait prise √©tant donn√© une valeur de $X$ et la valeur que $Y$ aurait prise √©tant donn√© une autre valeur de $X$.
En raison de l'accent mis sur les diff√©rences entre les r√©sultats, cette approche est parfois appel√©e approche "des diff√©rences"¬†ou "contrefactuelle" de la causalit√©.

__Technical Note:__

Les statisticiens emploient le framework des "r√©sultats potentiels" pour d√©crire les relations contrefactuelles.
Dans ce cadre, $Y_i(1)$ d√©signe le r√©sultat pour l'unit√© $i$ qui serait observ√© sous une condition (par exemple, si l'unit√© $i$ recevait un traitement)
et $Y_i(0)$ d√©signe le r√©sultat qui serait √™tre observ√© dans une autre condition (par exemple, si l'unit√© $i$ n'a pas re√ßu le traitement).
Un effet causal du traitement pour l'unit√© $i$ pourrait √™tre une simple diff√©rence des r√©sultats potentiels $œÑ_i=Y_i(1)‚àíY_i(0)$.
Un traitement a un effet causal (positif ou n√©gatif) sur $Y$ pour l'unit√© $i$ si $Y_i(1)‚â†Y_i(0)$.

[^2]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

2. Point de causalit√© sans manipulation.
==
La d√©finition "contrefactuelle" de la causalit√© exige que l'on soit capable de r√©fl√©chir aux r√©sultats qui peuvent entra√Æner des conditions diff√©rentes.
√Ä quoi ressembleraient les choses si un parti plut√¥t qu'un autre √©tait √©lu?
Les d√©clarations causales de tous les jours ne r√©pondent souvent pas √† cette exigence de l'une des deux mani√®res suivantes.

* Premi√®rement, certaines d√©clarations ne pr√©cisent pas de conditions contrefactuelles claires.
Par exemple, l'affirmation selon laquelle "la r√©cession a √©t√© caus√©e par Wall Street" n'indique pas un contrefactuel √©vident
--- devons-nous examiner s'il y aurait eu une r√©cession si Wall Street n'avait pas exist√© ?
Ou la d√©claration est-elle vraiment une d√©claration sur des actions particuli√®res que Wall Street aurait pu prendre mais n'a pas fait.
Si oui, quelles actions ? La validit√© de telles d√©clarations est difficile √† √©valuer et peut d√©pendre des conditions contrefactuelles impliqu√©es par une d√©claration.

* Deuxi√®mement, certaines d√©clarations impliquent des conditions contrefactuelles qui ne peuvent √™tre imagin√©es.
Par exemple, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est Peter implique une consid√©ration de ce qui se serait pass√© si Peter n'√©tait pas Peter.
Alternativement, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est un homme n√©cessite de consid√©rer Peter comme autre qu'un homme.
Le probl√®me est que les contrefactuels dans ces cas impliquent un changement non seulement dans la condition √† laquelle fait face un individu, mais dans l'individu lui-m√™me.

Pour √©viter de tels probl√®mes, certains statisticiens recommandent de restreindre les assertions causales aux traitements qui peuvent en th√©orie (pas n√©cessairement en pratique) √™tre manipul√©s.[^11]
Par exemple, alors que nous pourrions avoir des difficult√©s avec l'affirmation selon laquelle Peter a obtenu le poste parce qu'il √©tait un homme, nous n'avons pas de telles difficult√©s avec l'affirmation selon laquelle Peter a obtenu le poste parce que l'agence de recrutement pensait qu'il √©tait un homme.

[^11]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

3. Les causes ne sont pas rivales.
==

M√™me si nous pouvons nous concentrer sur l'effet d'une seule cause $X$ sur un r√©sultat $Y$, nous ne nous attendons g√©n√©ralement pas √† ce qu'il n'y ait jamais qu'une seule cause de $Y$.[^5]
De plus, si vous additionnez les effets causaux de diff√©rentes causes, il n'y a aucune raison de s'attendre √† ce qu'ils totalisent 100 %.
Par cons√©quent, il ne sert √† rien d'essayer de "r√©partir" les r√©sultats entre diff√©rents facteurs de causalit√©.
En d'autres termes, les causes ne sont pas rivales.
La National Rifle Association soutient, par exemple, que les armes √† feu ne tuent pas les gens, les gens tuent les gens.
Cette d√©claration n'a pas beaucoup de sens dans le cadre contrefactuel.
Enlevez les armes √† feu et vous n'aurez pas de morts par balles.
Les armes √† feu sont donc une cause.
Enlevez les gens et vous n'aurez pas non plus de d√©c√®s par balle, donc les gens sont aussi une cause.
En d'autres termes, ces deux facteurs sont simultan√©ment les causes des m√™mes r√©sultats.

[^5]: Certains appellent cela le "probl√®me des causes de prodigalit√©".


4. $X$ peut provoquer $Y$ m√™me si $X$ n'est pas une condition n√©cessaire ou une condition suffisante pour $Y$.
==
On parle souvent de relations causales en termes d√©terministes.
M√™me la citation de Lewis en haut de cette page semble sugg√©rer une relation d√©terministe entre les causes et les effets.
On pense parfois que les relations causales impliquent des conditions n√©cessaires (pour que $Y$ se produise, $X$ doit se produire); on pense parfois que de telles relations impliquent des conditions suffisantes (si $X$ se produit, alors $Y$ se produit).
Mais une fois que nous parlons d'unit√©s multiples, il y a au moins deux fa√ßons de penser que $X$ cause $Y$ m√™me si $X$ n'est ni une condition n√©cessaire ni une condition suffisante pour $Y$.
La premi√®re consiste √† tout r√©interpr√©ter en termes probabilistes : par $X$ cause $Y$, on entend simplement que la probabilit√© de $Y$ est plus √©lev√©e lorsque $X$ est pr√©sent.
Une autre consiste √† tenir compte des contingences --- par exemple, $X$ peut provoquer $Y$ si la condition $Z$ est pr√©sente, mais pas dans le cas contraire.[^9]

[^9]:
Mackie a pr√©sent√© l'id√©e de conditions dites "INSS" ("INUS" en anglais) pour capturer la d√©pendance des causes sur d'autres causes.
Une cause peut √™tre une partie *Insuffisante* mais *N√©cessaire* d'une condition qui est elle-m√™me *Superflue* mais *Suffisante*.
Par exemple, composer un num√©ro de t√©l√©phone est un motif pour contacter quelqu'un car avoir une connexion et composer un num√©ro est suffisant (S) pour passer un appel t√©l√©phonique,
alors que composer seul sans connexion ne suffirait pas (I), ni avoir un connexion (N).
Il existe bien s√ªr d'autres moyens de contacter quelqu'un sans passer d'appels t√©l√©phoniques (S).
Mackie, John L. "The cement of the universe." London: Oxford Uni (1974).

5. Le probl√®me fondamental d'inf√©rence causale.
==

Si les effets causaux sont des d√©clarations sur la diff√©rence entre ce qui s'est pass√© et ce qui aurait pu arriver, alors les effets causaux ne peuvent pas √™tre mesur√©s.
C'est une mauvaise nouvelle.
De mani√®re prospective, vous pouvez organiser les choses de mani√®re √† pouvoir observer ce qui se passe si une personne re√ßoit un traitement ou ce qui se passe si elle ne re√ßoit pas le traitement.
Pourtant, pour la m√™me personne, vous ne pourrez jamais observer ces deux r√©sultats et donc pas non plus la diff√©rence entre eux.
Cette incapacit√© √† observer les effets causaux au niveau de l'unit√© est souvent appel√©e le "probl√®me fondamental de l'inf√©rence causale".

6. Vous pouvez estimer l'effet causal moyen m√™me si vous ne pouvez pas observer d'effets causaux individuels.
==

M√™me si vous ne pouvez pas observer si $X$ cause $Y$ pour une unit√© donn√©e, il est toujours possible de d√©terminer si $X$ cause $Y$ en moyenne.
L'id√©e cl√© ici est que l'effet causal moyen est √©gal √† la diff√©rence entre le r√©sultat moyen pour toutes les unit√©s si toutes les unit√©s √©taient dans la condition de contr√¥le et le r√©sultat moyen pour toutes les unit√©s si toutes les unit√©s √©taient dans la condition de traitement.
De nombreuses strat√©gies d'identification causale (voir [10 strat√©gies pour d√©terminer si X a caus√© Y](http://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)) se concentrent sur des fa√ßons d'en savoir plus sur ces r√©sultats potentiels moyens.^[__Note technique¬†:__ La principale id√©e technique est que la diff√©rence des moyennes est la m√™me que la moyenne des diff√©rences.
C'est-√†-dire, en utilisant "l'op√©rateur d'esp√©rance", $ùîº(œÑ_i)=ùîº(Y_i(1)‚àíY_i(0))=ùîº(Y_i(1))‚àíùîº(Y_i(0))$.
Les termes √† l'int√©rieur de l'op√©rateur d'esp√©rance dans la deuxi√®me quantit√© ne peuvent pas √™tre estim√©s, mais les termes √† l'int√©rieur des op√©rateurs d'attentes dans la troisi√®me quantit√© peuvent l'√™tre.[^3] Voir l'illustration [ici](https://raw.githubusercontent.com/egap/ methodes-guides/master/causal-inference/PO.jpg).]

[10 choses √† savoir sur les tests d'hypoth√®se] (https://egap.org/resource/10-things-to-know-about-hypothesis-testing/) d√©crit comment on peut en savoir plus sur les effets causaux individuels plut√¥t que sur les effets causaux moyens √©tant donn√© le probl√®me fondamental de l'inf√©rence causale.

[^3]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

7. L'estimation de l'effet causal moyen ne n√©cessite pas que les groupes de traitement et de contr√¥le soient identiques.
==
Une strat√©gie que les gens utilisent pour en savoir plus sur l'effet causal moyen consiste √† cr√©er des groupes de traitement et de contr√¥le par randomisation (voir [10 Strat√©gies pour d√©terminer si X a caus√© Y] (http://egap.org/resource/10-strategies-for- d√©terminer-si-x-caus√©-y)).
Ce faisant, les chercheurs s'inqui√®tent parfois s'ils constatent que les groupes de traitement et de contr√¥le qui en r√©sultent ne se ressemblent pas selon les dimensions pertinentes.

La bonne nouvelle est que l'argument expliquant pourquoi les diff√©rences dans les r√©sultats moyens entre les groupes de traitement et de contr√¥le assign√©s de mani√®re al√©atoire capturent l'effet moyen de traitement (en esp√©rance pour des randomisations r√©p√©t√©es au sein du m√™me groupe d'unit√©s) ne repose *pas* sur le fait que les groupes de traitement et de contr√¥le ont des caract√©ristiques observ√©es similaires.
Il repose uniquement sur l'id√©e que, en moyenne, les r√©sultats dans les groupes trait√©s et t√©moins captureront les r√©sultats moyens pour toutes les unit√©s du groupe exp√©rimental si elles √©taient, respectivement, en traitement ou en contr√¥le.
En pratique, les groupes de traitement et de contr√¥le r√©els ne seront pas identiques.[^10]

[^10]: Pour cette raison, les tests-$t$ pour v√©rifier si "la randomisation a fonctionn√©" n'ont pas beaucoup de sens, du moins si vous savez qu'une proc√©dure randomis√©e a √©t√© suivie --- simplement par hasard, 1 test sur 20 montrera des diff√©rences statistiquement d√©tectables entre les groupes de traitement et de contr√¥le.
En cas de doute sur la mise en ≈ìuvre correcte d'une proc√©dure randomis√©e, ces tests peuvent √™tre utilis√©s pour tester l'hypoth√®se selon laquelle les donn√©es ont bien √©t√© g√©n√©r√©es par une proc√©dure randomis√©e.
Ces tests peuvent alors √™tre particuli√®rement importants pour des exp√©riences de terrain o√π les cha√Ænes de communication entre la personne randomisant et la personne mettant en ≈ìuvre l'assignation du traitement peuvent √™tre longues et complexes.

8. La corr√©lation n'est pas la causalit√©.
==

Une corr√©lation entre $X$ et $Y$ est une d√©claration sur les relations entre les r√©sultats r√©els dans le monde, et non sur la relation entre les r√©sultats r√©els et les r√©sultats contrefactuels.
Ainsi, les d√©clarations sur les causes et les corr√©lations n'ont pas grand-chose √† voir les unes avec les autres.
Des corr√©lations positives peuvent √™tre coh√©rentes avec des effets causaux positifs, aucun effet causal ou m√™me des effets causaux n√©gatifs.
Par exemple, la prise de m√©dicaments contre la toux est positivement corr√©l√©e √† la toux mais a, esp√©rons-le, un effet causal n√©gatif sur la toux.^[__Note technique¬†:__ Soit $D_i$ un indicateur pour savoir si l'unit√© $i$ a re√ßu un traitement ou non.

Alors, la diff√©rence de r√©sultats moyens entre ceux qui re√ßoivent le traitement et ceux qui n'en re√ßoivent pas peut s'√©crire $\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}‚àí\frac{‚àë_i (1‚àíD_i)√ó Y_i(0)}{‚àë_i (1‚àíD_i)}$.
En l'absence d'informations sur la mani√®re dont le traitement a √©t√© assign√©, nous ne pouvons pas dire si cette diff√©rence est un bon estimateur de l'effet moyen du traitement, c'est-√†-dire de la diff√©rence entre les r√©sultats potentiels moyens pour les groupes de traitement et de contr√¥le pour toutes les unit√©s.
Ce qui importe est de savoir si $\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}$ est une bonne estimation de $\frac{‚àë_i 1√óY_i(1)}{‚àë_i1}$ et si $\frac {‚àë_i (1‚àíD_i)√óY_i(0)}{‚àë_i (1‚àíD_i)}$ est une bonne estimation de $\frac{‚àë_i 1√óY_i(0)}{‚àë_i1}$.
Cela pourrait √™tre le cas si ceux qui ont re√ßu un traitement sont un √©chantillon repr√©sentatif de toutes les unit√©s, mais sinon il n'y a aucune raison de s'attendre √† ce qu'il le soit.]

9. Si vous savez qu'en moyenne $A$ cause $B$ et $B$ cause $C$, cela ne veut pas dire qu'en moyenne $A$ cause $C$.

Vous pourriez vous attendre √† ce que si $A$ cause $B$ et $B$ cause $C$, alors $A$ cause $C$.[^12]
Mais il n'y a aucune raison de croire que les relations causales moyennes sont transitives de cette mani√®re.
Pour voir pourquoi, imaginez que $A$ a caus√© $B$ pour les hommes mais pas les femmes et $B$ a caus√© $C$ pour les femmes mais pas les hommes.
Ensuite, en moyenne, $A$ cause $B$ et $B$ cause $C$, mais il se peut qu'il n'y ait toujours personne pour qui $A$ cause $C$ √† $B$.

[^12]: Interpr√©tez "$A$ cause $B$, en moyenne" comme "l'effet moyen de $A$ sur $B$ est positif".

10. Il est plus facile d'en apprendre davantage sur les "effets des causes" que sur les "causes des effets".
==

Bien que cela puisse sembler √™tre deux fa√ßons de dire la m√™me chose, il y a une diff√©rence entre comprendre quel est l'effet de $X$ sur $Y$ (les "effets d'une cause") et si un r√©sultat $Y$ √©tait *d√ª* √† une cause $X$ (la "cause d'un effet").[^6] Consid√©rez l'exemple suivant.
Supposons que nous menions une exp√©rience avec un √©chantillon qui contient un nombre √©gal d'hommes et de femmes.
L'exp√©rience assigne de mani√®re al√©atoire des hommes et des femmes √† un traitement binaire $X$ et mesure un r√©sultat binaire $Y$.
De plus, supposons que $X$ ait un effet positif de 1 pour tous les hommes, c'est-√†-dire
le r√©sultat potentiel de contr√¥le des hommes est de z√©ro ($Y_i(0) = 0$) et leur r√©sultat potentiel trait√© est de un ($Y_i(1) = 1$).
Pour toutes les femmes, $X$ a un effet n√©gatif de $-1$, c'est-√†-dire que le r√©sultat potentiel de contr√¥le des femmes est de un ($Y_i(0) = 1$) et leur r√©sultat potentiel trait√© est de z√©ro ($Y_i(1) = 0$).
Dans cet exemple, l'effet moyen de $X$ sur $Y$ est nul.
Mais pour tous les participants du groupe de traitement avec $Y=1$, il est vrai que $Y=1$ *car* $X=1$.
De m√™me, pour tous les participants du groupe de traitement avec $Y=0$, il est vrai que $Y=0$ *car* $X=1$.
L'exp√©rimentation peut obtenir une r√©ponse exacte √† la question sur les "effets d'une cause", mais il n'est g√©n√©ralement pas possible d'obtenir une r√©ponse exacte √† la question sur la "cause d'un effet".[^7]

[^6]: Certains r√©interpr√®tent la question des "causes des effets" comme suit¬†: quelles sont les causes qui ont des effets sur les r√©sultats. Voir Andrew Gelman and Guido Imbens, "Why ask why? Forward causal inference and reverse causal questions", NBER Working Paper No. 19614 (Nov. 2013).
[^7]: Voir, par exemple, Tian, J., Pearl, J. 2000. "Probabilities of Causation: Bounds and Identification." Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.
